{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from perceiver import tokenize_data, CustomDataset, PerceiverBlock, Perceiver, CombinedModel\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed) #torch를 거치는 모든 난수들의 생성순서를 고정한다\n",
    "    torch.cuda.manual_seed(seed) #cuda를 사용하는 메소드들의 난수시드는 따로 고정해줘야한다 \n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True #딥러닝에 특화된 CuDNN의 난수시드도 고정 \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed) #numpy를 사용할 경우 고정\n",
    "    random.seed(seed) #파이썬 자체 모듈 random 모듈의 시드 고정\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/jisoo/n24news/n24news/captions_and_labels.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "groups = [\n",
    "    ['Opinion', 'Food', 'Movies'],\n",
    "    ['Art & Design', 'Science', 'Fashion & Style'],\n",
    "    ['Television', 'Sports', 'Style'],\n",
    "    ['Music', 'Health', 'Dance'],\n",
    "    ['Real Estate', 'Books', 'Media'],\n",
    "    ['Travel', 'Theater', 'Technology']\n",
    "]\n",
    "\n",
    "output_paths = []\n",
    "for i, group_labels in enumerate(groups, 1):\n",
    "    group_data = data[data['Label'].isin(group_labels)]\n",
    "    output_path = f'/home/jisoo/n24news/n24news/regroup_{i}.csv'\n",
    "    group_data.to_csv(output_path, index=False)\n",
    "    output_paths.append(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "MAX_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/Minju/Perceiver/model/'\n",
    "loader_dir = '/home/Minju/Perceiver/loader/'\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, input_ids, labels):\n",
    "#         self.input_ids = input_ids\n",
    "#         self.labels = labels\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return {\n",
    "#             'input_ids': self.input_ids[idx],\n",
    "#             'labels': self.labels[idx]\n",
    "#         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model, Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163727/3027492582.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  text_model = torch.load(root_dir + f'text_model_{i+1}.pkl')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text model 1번 불러오기 완료.\n",
      "Text model 2번 불러오기 완료.\n",
      "Text model 3번 불러오기 완료.\n",
      "Text model 4번 불러오기 완료.\n",
      "Text model 5번 불러오기 완료.\n",
      "Text model 6번 불러오기 완료.\n"
     ]
    }
   ],
   "source": [
    "input_models = []\n",
    "valid_loaders = []\n",
    "for i in range (6):\n",
    "    text_model = torch.load(root_dir + f'text_model_{i+1}.pkl')\n",
    "    input_models.append(text_model)\n",
    "    print(f\"Text model {i+1}번 불러오기 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image model 0번 불러오기 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163727/2086765618.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  img_model = torch.load(root_dir + f'image_model_{i+1}.pkl')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image model 1번 불러오기 완료.\n",
      "Image model 2번 불러오기 완료.\n",
      "Image model 3번 불러오기 완료.\n",
      "Image model 4번 불러오기 완료.\n",
      "Image model 5번 불러오기 완료.\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    img_model = torch.load(root_dir + f'image_model_{i+1}.pkl')\n",
    "    input_models.append(img_model)\n",
    "    print(f\"Image model {i}번 불러오기 완료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주의: 현재 text 모달리티는 dataloader 자체가 저장되어있지만 image 모달리티는 데이터가 그대로 저장되어있어 Dataloader로 변환해주어야 합니다. \\\n",
    "일단 지금은 이대로 두지만 언젠가 에러나면 수정이 필요합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text val. loader 0번 불러오기 완료.\n",
      "Text val. loader 1번 불러오기 완료.\n",
      "Text val. loader 2번 불러오기 완료.\n",
      "Text val. loader 3번 불러오기 완료.\n",
      "Text val. loader 4번 불러오기 완료.\n",
      "Text val. loader 5번 불러오기 완료.\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    with open(loader_dir+f'text_val_loader_{i+1}.pkl', 'rb') as f:\n",
    "        loaded_valid_dataset = pickle.load(f)\n",
    "    valid_loaders.append(loaded_valid_dataset)\n",
    "    print(f\"Text val. loader {i}번 불러오기 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image val. loader 0번 불러오기 완료.\n",
      "Image val. loader 1번 불러오기 완료.\n",
      "Image val. loader 2번 불러오기 완료.\n",
      "Image val. loader 3번 불러오기 완료.\n",
      "Image val. loader 4번 불러오기 완료.\n",
      "Image val. loader 5번 불러오기 완료.\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    with open(loader_dir+f'image_val_loader_{i+1}.pkl', 'rb') as f:\n",
    "        loaded_valid_dataset = pickle.load(f)\n",
    "\n",
    "    valid_loader = DataLoader(loaded_valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    valid_loaders.append(valid_loader)\n",
    "    print(f\"Image val. loader {i}번 불러오기 완료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PackNet Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PackNet(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(PackNet, self).__init__()\n",
    "        self.model = model\n",
    "        self.masks = {}\n",
    "        self.current_task = None\n",
    "\n",
    "    def set_task(self, task_id):\n",
    "        self.current_task = task_id\n",
    "        if task_id not in self.masks:\n",
    "            self.masks[task_id] = {\n",
    "                name: torch.ones_like(param, device=param.device)\n",
    "                for name, param in self.model.named_parameters()\n",
    "                if param.requires_grad\n",
    "            }\n",
    "\n",
    "    def prune(self, sparsity=0.2):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                mask = self.masks[self.current_task][name]\n",
    "                threshold = torch.quantile(param.abs(), sparsity)\n",
    "                mask[param.abs() < threshold] = 0\n",
    "                self.masks[self.current_task][name] = mask\n",
    "\n",
    "    def forward(self, input_ids, **kwargs):\n",
    "        if self.current_task in self.masks:\n",
    "            with torch.no_grad():\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if param.requires_grad:\n",
    "                        param.data *= self.masks[self.current_task][name]\n",
    "        return self.model(input_ids, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return total_loss / len(dataloader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return total_loss / len(dataloader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "BATCH_SIZE = 32\n",
    "K_FOLDS = 1\n",
    "EMBED_DIM = 128  \n",
    "LATENT_DIM = 64\n",
    "LATENT_SIZE = 64\n",
    "NUM_BLOCKS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pruning_with_intervals(packnet_model, test_loader, criterion, device, start_sparsity, end_sparsity, pruning_ratio):\n",
    "    \n",
    "    current_sparsity = start_sparsity\n",
    "    while current_sparsity <= end_sparsity:\n",
    "        print(f\"Applying pruning with sparsity: {current_sparsity:.2f}\")\n",
    "        packnet_model.prune(sparsity=current_sparsity)\n",
    "\n",
    "        # Evaluate after pruning if test_loader is provided\n",
    "        if test_loader is not None and criterion is not None:\n",
    "            print(\"Evaluating after pruning...\")\n",
    "            pruned_test_loss, pruned_test_acc = eval_epoch(packnet_model, test_loader, criterion, device)\n",
    "            print(f\"Pruned Test Loss: {pruned_test_loss:.4f}, Test Accuracy: {pruned_test_acc:.4f}\")\n",
    "        else:\n",
    "            print(f\"Skipping evaluation as 'test_loader' or 'criterion' is None.\")\n",
    "\n",
    "        current_sparsity += pruning_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group 1 처리 중...\n",
      "\n",
      "  Fold 1/5 처리 중...\n",
      "Pruning 이전 성능:\n",
      "  Test Loss: 1.1050, Test Accuracy: 0.3211\n",
      "epoch 1/15: train loss 1.1071, train acc 0.3487\n",
      "                         test loss 1.0765, test acc 0.4196\n",
      "epoch 5/15: train loss 0.5272, train acc 0.7929\n",
      "                         test loss 0.5932, test acc 0.7642\n",
      "epoch 10/15: train loss 0.3620, train acc 0.8683\n",
      "                         test loss 0.4440, test acc 0.8266\n",
      "epoch 15/15: train loss 0.2931, train acc 0.8957\n",
      "                         test loss 0.4660, test acc 0.8204\n",
      "\n",
      "  Fold 2/5 처리 중...\n",
      "Pruning 이전 성능:\n",
      "  Test Loss: 1.1135, Test Accuracy: 0.3366\n",
      "epoch 1/15: train loss 1.1084, train acc 0.3575\n",
      "                         test loss 1.0853, test acc 0.4358\n",
      "epoch 5/15: train loss 0.5043, train acc 0.8123\n",
      "                         test loss 0.4810, test acc 0.8307\n",
      "epoch 10/15: train loss 0.3644, train acc 0.8661\n",
      "                         test loss 0.3971, test acc 0.8584\n",
      "epoch 15/15: train loss 0.3082, train acc 0.8902\n",
      "                         test loss 0.3866, test acc 0.8661\n",
      "\n",
      "  Fold 3/5 처리 중...\n",
      "Pruning 이전 성능:\n",
      "  Test Loss: 1.0983, Test Accuracy: 0.3484\n",
      "epoch 1/15: train loss 1.1068, train acc 0.3518\n",
      "                         test loss 1.0812, test acc 0.3518\n",
      "epoch 5/15: train loss 0.4466, train acc 0.8304\n",
      "                         test loss 0.4098, test acc 0.8418\n",
      "epoch 10/15: train loss 0.3174, train acc 0.8904\n",
      "                         test loss 0.3917, test acc 0.8577\n",
      "epoch 15/15: train loss 0.2699, train acc 0.9082\n",
      "                         test loss 0.3992, test acc 0.8612\n",
      "\n",
      "  Fold 4/5 처리 중...\n",
      "Pruning 이전 성능:\n",
      "  Test Loss: 1.1002, Test Accuracy: 0.3720\n",
      "epoch 1/15: train loss 1.1057, train acc 0.3611\n",
      "                         test loss 1.0721, test acc 0.4205\n",
      "epoch 5/15: train loss 0.4855, train acc 0.8201\n",
      "                         test loss 0.4805, test acc 0.8223\n",
      "epoch 10/15: train loss 0.3654, train acc 0.8670\n",
      "                         test loss 0.4379, test acc 0.8362\n",
      "epoch 15/15: train loss 0.3064, train acc 0.8925\n",
      "                         test loss 0.4200, test acc 0.8466\n",
      "\n",
      "  Fold 5/5 처리 중...\n",
      "Pruning 이전 성능:\n",
      "  Test Loss: 1.1021, Test Accuracy: 0.3525\n",
      "epoch 1/15: train loss 1.0966, train acc 0.3702\n",
      "                         test loss 0.9434, test acc 0.5781\n",
      "epoch 5/15: train loss 0.5139, train acc 0.8116\n",
      "                         test loss 0.5114, test acc 0.8119\n",
      "epoch 10/15: train loss 0.3372, train acc 0.8812\n",
      "                         test loss 0.4528, test acc 0.8522\n",
      "epoch 15/15: train loss 0.2755, train acc 0.9063\n",
      "                         test loss 0.4355, test acc 0.8577\n",
      "\n",
      "그룹 1의 5 폴드 평균 테스트 정확도: 0.8504\n",
      "Average model checkpoint for Group 1 saved at /home/jisoo/Perceiver/Perceiver/checkpoints/group_1_average_model.pth.tar\n",
      "Confusion Matrix for Fold 1 is invalid or missing.\n",
      "plt 뽑히려던 곳 \n",
      "Confusion Matrix for Fold 2 is invalid or missing.\n",
      "plt 뽑히려던 곳 \n",
      "Confusion Matrix for Fold 3 is invalid or missing.\n",
      "plt 뽑히려던 곳 \n",
      "Confusion Matrix for Fold 4 is invalid or missing.\n",
      "plt 뽑히려던 곳 \n",
      "Confusion Matrix for Fold 5 is invalid or missing.\n",
      "plt 뽑히려던 곳 \n",
      "\n",
      "Group 2 처리 중...\n",
      "\n",
      "  Fold 1/5 처리 중...\n",
      "Pruning 이전 성능:\n",
      "  Test Loss: 1.1092, Test Accuracy: 0.3366\n",
      "epoch 1/15: train loss 1.0832, train acc 0.3919\n",
      "                         test loss 1.0641, test acc 0.4455\n",
      "epoch 5/15: train loss 0.7819, train acc 0.6703\n",
      "                         test loss 0.7409, test acc 0.6974\n",
      "epoch 10/15: train loss 0.5788, train acc 0.7692\n",
      "                         test loss 0.6305, test acc 0.7432\n",
      "epoch 15/15: train loss 0.4896, train acc 0.8127\n",
      "                         test loss 0.5613, test acc 0.7696\n",
      "\n",
      "  Fold 2/5 처리 중...\n",
      "Pruning 이전 성능:\n",
      "  Test Loss: 1.3122, Test Accuracy: 0.3373\n",
      "epoch 1/15: train loss 1.0771, train acc 0.4098\n",
      "                         test loss 1.0530, test acc 0.4421\n",
      "epoch 5/15: train loss 0.7719, train acc 0.6734\n",
      "                         test loss 0.7494, test acc 0.6683\n",
      "epoch 10/15: train loss 0.5844, train acc 0.7678\n",
      "                         test loss 0.6761, test acc 0.7273\n",
      "epoch 15/15: train loss 0.5065, train acc 0.8027\n",
      "                         test loss 0.6453, test acc 0.7342\n",
      "\n",
      "  Fold 3/5 처리 중...\n",
      "Pruning 이전 성능:\n",
      "  Test Loss: 1.1243, Test Accuracy: 0.3380\n",
      "epoch 1/15: train loss 1.0805, train acc 0.4099\n",
      "                         test loss 1.0450, test acc 0.4074\n",
      "epoch 5/15: train loss 0.6823, train acc 0.7223\n",
      "                         test loss 0.7221, test acc 0.6877\n",
      "epoch 10/15: train loss 0.4978, train acc 0.8056\n",
      "                         test loss 0.6042, test acc 0.7627\n",
      "epoch 15/15: train loss 0.4250, train acc 0.8389\n",
      "                         test loss 0.5904, test acc 0.7668\n",
      "\n",
      "  Fold 4/5 처리 중...\n",
      "Pruning 이전 성능:\n",
      "  Test Loss: 1.1613, Test Accuracy: 0.3250\n",
      "epoch 1/15: train loss 1.0608, train acc 0.4223\n",
      "                         test loss 0.9600, test acc 0.5153\n",
      "epoch 5/15: train loss 0.7471, train acc 0.6773\n",
      "                         test loss 0.7040, test acc 0.7021\n",
      "epoch 10/15: train loss 0.4789, train acc 0.8140\n",
      "                         test loss 0.5897, test acc 0.7611\n",
      "epoch 15/15: train loss 0.4108, train acc 0.8447\n",
      "                         test loss 0.6235, test acc 0.7611\n",
      "\n",
      "  Fold 5/5 처리 중...\n",
      "Pruning 이전 성능:\n",
      "  Test Loss: 1.1343, Test Accuracy: 0.3368\n",
      "epoch 1/15: train loss 1.0934, train acc 0.3786\n",
      "                         test loss 1.0252, test acc 0.4653\n",
      "epoch 5/15: train loss 0.7528, train acc 0.6835\n",
      "                         test loss 0.7286, test acc 0.7035\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_test_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_test_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m---> 67\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacknet_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m eval_epoch(packnet_model, test_loader, criterion, device)\n\u001b[1;32m     70\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 15\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "all_learning_curves = []\n",
    "\n",
    "for idx, group_file in enumerate(output_paths, start=1):\n",
    "    print(f\"\\nGroup {idx} 처리 중...\")\n",
    "\n",
    "    df = pd.read_csv(group_file)\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['Label'] = label_encoder.fit_transform(df['Label'])\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "\n",
    "    input_ids, attention_masks = tokenize_data(df)\n",
    "    labels = torch.tensor(df['Label'].values)\n",
    "\n",
    "    dataset = CustomDataset(input_ids, attention_masks, labels)\n",
    "    kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_results = []\n",
    "    fold_learning_curves = []\n",
    "\n",
    "    averaged_state_dict = None\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(dataset), start=1):\n",
    "        print(f\"\\n  Fold {fold}/{K_FOLDS} 처리 중...\")\n",
    "\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        test_subset = Subset(dataset, test_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        # Perceiver 모델 초기화\n",
    "        perceiver = Perceiver(\n",
    "            input_dim=EMBED_DIM,\n",
    "            latent_dim=LATENT_DIM,\n",
    "            latent_size=LATENT_SIZE,\n",
    "            num_classes=num_classes,\n",
    "            num_blocks=NUM_BLOCKS,\n",
    "            self_attn_layers_per_block=1\n",
    "        )\n",
    "\n",
    "        # CombinedModel 초기화\n",
    "        combined_model = CombinedModel(\n",
    "            vocab_size=tokenizer.vocab_size,\n",
    "            embed_dim=EMBED_DIM,\n",
    "            perceiver_model=perceiver\n",
    "        )\n",
    "\n",
    "        # PackNet\n",
    "        packnet_model = PackNet(combined_model)\n",
    "        packnet_model.to(device)\n",
    "        packnet_model.set_task(f\"task_{idx}_{fold}\")\n",
    "\n",
    "        optimizer = optim.Adam(packnet_model.parameters(), lr=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        train_losses, test_losses = [], []\n",
    "        train_accuracies, test_accuracies = [], []\n",
    "\n",
    "        # Pruning 이전 성능 평가\n",
    "        print(\"Pruning 이전 성능:\")\n",
    "        initial_test_loss, initial_test_acc = eval_epoch(packnet_model, test_loader, criterion, device)\n",
    "        print(f\"  Test Loss: {initial_test_loss:.4f}, Test Accuracy: {initial_test_acc:.4f}\")\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss, train_acc = train_epoch(packnet_model, train_loader, criterion, optimizer, device)\n",
    "            test_loss, test_acc = eval_epoch(packnet_model, test_loader, criterion, device)\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            test_losses.append(test_loss)\n",
    "            train_accuracies.append(train_acc)\n",
    "            test_accuracies.append(test_acc)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "                print(f\"epoch {epoch+1}/{EPOCHS}: train loss {train_loss:.4f}, train acc {train_acc:.4f}\")\n",
    "                print(f\"                         test loss {test_loss:.4f}, test acc {test_acc:.4f}\")\n",
    "\n",
    "        # Fold 모델 상태 저장 및 평균 계산\n",
    "        state_dict = packnet_model.state_dict()\n",
    "        if averaged_state_dict is None:\n",
    "            averaged_state_dict = {key: val.clone() for key, val in state_dict.items()}\n",
    "        else:\n",
    "            for key in averaged_state_dict:\n",
    "                averaged_state_dict[key] += state_dict[key]\n",
    "\n",
    "        \n",
    "        # 결과 저장\n",
    "        fold_results.append({\n",
    "            \"Fold\": fold,\n",
    "            \"Test Accuracy\": test_acc,\n",
    "            \"Confusion Matrix\": None,\n",
    "            \"Classification Report\": None\n",
    "        })\n",
    "        # learning curve\n",
    "        fold_learning_curves.append({\n",
    "            \"Fold\": fold,\n",
    "            \"train_losses\": train_losses,\n",
    "            \"test_losses\": test_losses,\n",
    "            \"train_accuracies\": train_accuracies,\n",
    "            \"test_accuracies\": test_accuracies\n",
    "        })\n",
    "\n",
    "        # confusion matrix\n",
    "        y_true, y_pred = [], []\n",
    "        packnet_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                input_ids_batch = batch['input_ids'].to(device)\n",
    "                labels_batch = batch['labels'].to(device)\n",
    "\n",
    "                outputs = packnet_model(input_ids_batch)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                y_true.extend(labels_batch.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        if cm.ndim != 2:\n",
    "            raise ValueError(f\"Confusion Matrix must be 2D, but got shape {cm.shape}.\")\n",
    "        report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "        fold_results.append({\n",
    "        \"Fold\": fold,\n",
    "        \"Test Accuracy\": test_acc,\n",
    "        \"Confusion Matrix\": cm,\n",
    "        \"Classification Report\": classification_report(y_true, y_pred, output_dict=True)\n",
    "        })\n",
    "    \n",
    "    avg_accuracy = np.mean([fr[\"Test Accuracy\"] for fr in fold_results])\n",
    "    results.append({\n",
    "        \"Group\": idx,\n",
    "        \"Average Test Accuracy\": avg_accuracy,\n",
    "        \"Fold Results\": fold_results\n",
    "    })\n",
    "\n",
    "    all_learning_curves.append({\n",
    "        \"Group\": idx,\n",
    "        \"Fold Learning Curves\": fold_learning_curves\n",
    "    })\n",
    "\n",
    "    print(f\"\\n그룹 {idx}의 {K_FOLDS} 폴드 평균 테스트 정확도: {avg_accuracy:.4f}\")\n",
    "\n",
    "    # 평균 모델 저장\n",
    "    checkpoint_path = f\"/home/jisoo/Perceiver/Perceiver/checkpoints/group_{idx}_average_model.pth.tar\"\n",
    "    torch.save(averaged_state_dict, checkpoint_path)\n",
    "    print(f\"Average model checkpoint for Group {idx} saved at {checkpoint_path}\")\n",
    "\n",
    "    avg_accuracy = np.mean([fr[\"Test Accuracy\"] for fr in fold_results])\n",
    "\n",
    "    for curve in fold_learning_curves:\n",
    "        fold_idx = curve[\"Fold\"]\n",
    "\n",
    "      \n",
    "        # plt.figure(figsize=(10, 6))\n",
    "        # plt.plot(range(1, EPOCHS + 1), curve[\"train_losses\"], label=\"Train Loss\")\n",
    "        # plt.plot(range(1, EPOCHS + 1), curve[\"test_losses\"], label=\"Test Loss\")\n",
    "        # plt.title(f\"Group {idx} - Fold {fold_idx} Learning Curve (Loss)\")\n",
    "        # plt.xlabel(\"Epoch\")\n",
    "        # plt.ylabel(\"Loss\")\n",
    "        # plt.legend()\n",
    "        # plt.grid(True)\n",
    "        # plt.show()\n",
    "\n",
    "    \n",
    "        # plt.figure(figsize=(10, 6))\n",
    "        # plt.plot(range(1, EPOCHS + 1), curve[\"train_accuracies\"], label=\"Train Accuracy\")\n",
    "        # plt.plot(range(1, EPOCHS + 1), curve[\"test_accuracies\"], label=\"Test Accuracy\")\n",
    "        # plt.title(f\"Group {idx} - Fold {fold_idx} Learning Curve (Accuracy)\")\n",
    "        # plt.xlabel(\"Epoch\")\n",
    "        # plt.ylabel(\"Accuracy\")\n",
    "        # plt.legend()\n",
    "        # plt.grid(True)\n",
    "        # plt.show()\n",
    "\n",
    "    for fold_result in fold_results:\n",
    "        fold_idx = fold_result[\"Fold\"]\n",
    "        cm = fold_result[\"Confusion Matrix\"]\n",
    "\n",
    "        if cm is not None and cm.ndim == 2:\n",
    "            # plt.figure(figsize=(10, 8))\n",
    "            # sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            #             xticklabels=label_encoder.classes_,\n",
    "            #             yticklabels=label_encoder.classes_)\n",
    "            # plt.title(f\"Group {idx} - Fold {fold_idx} Confusion Matrix\")\n",
    "            # plt.xlabel(\"Predicted\")\n",
    "            # plt.ylabel(\"Actual\")\n",
    "            # plt.show()\n",
    "            print(\"plt 뽑히려던 곳 \")\n",
    "        else:\n",
    "            print(f\"Confusion Matrix for Fold {fold_idx} is invalid or missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint for Group 1 from /home/jisoo/Perceiver/Perceiver/checkpoints/group_1_average_model.pth.tar...\n",
      "Model successfully loaded with matched parameters.\n",
      "Applying pruning with sparsity: 0.05\n",
      "Applying pruning with sparsity: 0.10\n",
      "Applying pruning with sparsity: 0.15\n",
      "Applying pruning with sparsity: 0.20\n",
      "Pruning completed.\n",
      "Pruned model for Group 1 saved at /home/jisoo/Perceiver/Perceiver/checkpoints/group_1_pruned_model.pth.tar.\n",
      "Loading checkpoint for Group 2 from /home/jisoo/Perceiver/Perceiver/checkpoints/group_2_average_model.pth.tar...\n",
      "Model successfully loaded with matched parameters.\n",
      "Applying pruning with sparsity: 0.05\n",
      "Applying pruning with sparsity: 0.10\n",
      "Applying pruning with sparsity: 0.15\n",
      "Applying pruning with sparsity: 0.20\n",
      "Pruning completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_154851/4049929000.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model for Group 2 saved at /home/jisoo/Perceiver/Perceiver/checkpoints/group_2_pruned_model.pth.tar.\n",
      "Loading checkpoint for Group 3 from /home/jisoo/Perceiver/Perceiver/checkpoints/group_3_average_model.pth.tar...\n",
      "Model successfully loaded with matched parameters.\n",
      "Applying pruning with sparsity: 0.05\n",
      "Applying pruning with sparsity: 0.10\n",
      "Applying pruning with sparsity: 0.15\n",
      "Applying pruning with sparsity: 0.20\n",
      "Pruning completed.\n",
      "Pruned model for Group 3 saved at /home/jisoo/Perceiver/Perceiver/checkpoints/group_3_pruned_model.pth.tar.\n",
      "Loading checkpoint for Group 4 from /home/jisoo/Perceiver/Perceiver/checkpoints/group_4_average_model.pth.tar...\n",
      "Model successfully loaded with matched parameters.\n",
      "Applying pruning with sparsity: 0.05\n",
      "Applying pruning with sparsity: 0.10\n",
      "Applying pruning with sparsity: 0.15\n",
      "Applying pruning with sparsity: 0.20\n",
      "Pruning completed.\n",
      "Pruned model for Group 4 saved at /home/jisoo/Perceiver/Perceiver/checkpoints/group_4_pruned_model.pth.tar.\n",
      "Loading checkpoint for Group 5 from /home/jisoo/Perceiver/Perceiver/checkpoints/group_5_average_model.pth.tar...\n",
      "Model successfully loaded with matched parameters.\n",
      "Applying pruning with sparsity: 0.05\n",
      "Applying pruning with sparsity: 0.10\n",
      "Applying pruning with sparsity: 0.15\n",
      "Applying pruning with sparsity: 0.20\n",
      "Pruning completed.\n",
      "Pruned model for Group 5 saved at /home/jisoo/Perceiver/Perceiver/checkpoints/group_5_pruned_model.pth.tar.\n",
      "Loading checkpoint for Group 6 from /home/jisoo/Perceiver/Perceiver/checkpoints/group_6_average_model.pth.tar...\n",
      "Model successfully loaded with matched parameters.\n",
      "Applying pruning with sparsity: 0.05\n",
      "Applying pruning with sparsity: 0.10\n",
      "Applying pruning with sparsity: 0.15\n",
      "Applying pruning with sparsity: 0.20\n",
      "Pruning completed.\n",
      "Pruned model for Group 6 saved at /home/jisoo/Perceiver/Perceiver/checkpoints/group_6_pruned_model.pth.tar.\n"
     ]
    }
   ],
   "source": [
    "def prune_model(group_idx, checkpoint_dir, start_sparsity, end_sparsity, pruning_ratio, device):\n",
    "    \n",
    "    # 기존 모델 로딩\n",
    "    checkpoint_path = f\"{checkpoint_dir}/group_{group_idx}_average_model.pth.tar\"\n",
    "    print(f\"Loading checkpoint for Group {group_idx} from {checkpoint_path}...\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "    num_classes = checkpoint.get('num_classes', checkpoint['model.perceiver.output_layer.weight'].size(0))\n",
    "\n",
    "    perceiver = Perceiver(\n",
    "        input_dim=128, \n",
    "        latent_dim=64,\n",
    "        latent_size=64,\n",
    "        num_classes=num_classes,\n",
    "        num_blocks=4,\n",
    "        self_attn_layers_per_block=1\n",
    "    )\n",
    "\n",
    "    combined_model = CombinedModel(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        embed_dim=128,\n",
    "        perceiver_model=perceiver\n",
    "    )\n",
    "\n",
    "    packnet_model = PackNet(combined_model)\n",
    "    model_state_dict = checkpoint\n",
    "\n",
    "    # 일치하지 않는 키 필터링\n",
    "    filtered_state_dict = {\n",
    "        key: value\n",
    "        for key, value in model_state_dict.items()\n",
    "        if key in packnet_model.state_dict() and packnet_model.state_dict()[key].size() == value.size()\n",
    "    }\n",
    "    packnet_model.load_state_dict(filtered_state_dict, strict=False)\n",
    "    packnet_model.to(device)\n",
    "    packnet_model.set_task(f\"group_{group_idx}_pruning\")\n",
    "    print(\"Model successfully loaded with matched parameters.\")\n",
    "\n",
    "    # 가중치 보고 pruning\n",
    "    current_sparsity = start_sparsity\n",
    "    while current_sparsity <= end_sparsity:\n",
    "        print(f\"Applying pruning with sparsity: {current_sparsity:.2f}\")\n",
    "        for name, module in packnet_model.named_modules():\n",
    "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "                weights = module.weight.data.abs().flatten()\n",
    "                threshold = torch.quantile(weights, current_sparsity)\n",
    "                mask = module.weight.data.abs() >= threshold\n",
    "                module.weight.data *= mask\n",
    "\n",
    "                # 마스크 선택적으로 저장\n",
    "                if not hasattr(module, 'mask'):\n",
    "                    module.mask = mask\n",
    "\n",
    "        current_sparsity += pruning_ratio\n",
    "\n",
    "    print(\"Pruning completed.\")\n",
    "\n",
    "    # pruned model 저장\n",
    "    pruned_checkpoint_path = f\"{checkpoint_dir}/group_{group_idx}_pruned_model.pth.tar\"\n",
    "    torch.save({\n",
    "        \"model_state_dict\": packnet_model.state_dict(),\n",
    "        \"num_classes\": num_classes,  # Replace with actual number of classes\n",
    "        \"vocab_size\": tokenizer.vocab_size\n",
    "    }, pruned_checkpoint_path)\n",
    "    print(f\"Pruned model for Group {group_idx} saved at {pruned_checkpoint_path}.\")\n",
    "\n",
    "# pruning 파라미터\n",
    "groups = [1, 2, 3, 4, 5, 6]  \n",
    "checkpoint_dir = \"/home/jisoo/Perceiver/Perceiver/checkpoints\"\n",
    "start_sparsity = 0.05\n",
    "end_sparsity = 0.2\n",
    "pruning_ratio = 0.05\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "for group_idx in groups:\n",
    "    prune_model(\n",
    "        group_idx=group_idx,\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        start_sparsity=start_sparsity,\n",
    "        end_sparsity=end_sparsity,\n",
    "        pruning_ratio=pruning_ratio,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_loader(group_idx, batch_size=32):\n",
    "    \n",
    "    group_file = output_paths[group_idx - 1]\n",
    "    df = pd.read_csv(group_file)\n",
    "\n",
    "   \n",
    "    input_ids = tokenize_data(df)\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['Label'] = label_encoder.fit_transform(df['Label'])\n",
    "    labels = torch.tensor(df['Label'].values)\n",
    "    test_dataset = CustomDataset(input_ids, labels)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return test_loader, label_encoder\n",
    "\n",
    "def load_pruned_model(group_idx, checkpoint_dir, device):\n",
    "    \n",
    "    checkpoint_path = f\"{checkpoint_dir}/group_{group_idx}_pruned_model.pth.tar\"\n",
    "    print(f\"Loading pruned model for Group {group_idx} from {checkpoint_path}...\")\n",
    "\n",
    "    # checkpoint 로드\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    num_classes = checkpoint.get('num_classes', 10)  # Use default if not in checkpoint\n",
    "\n",
    "    # 모델 초기화\n",
    "    perceiver = Perceiver(\n",
    "        input_dim=128,  # Match embedding dimension\n",
    "        latent_dim=64,\n",
    "        latent_size=64,\n",
    "        num_classes=num_classes,\n",
    "        num_blocks=4,\n",
    "        self_attn_layers_per_block=1\n",
    "    )\n",
    "\n",
    "    combined_model = CombinedModel(\n",
    "        vocab_size=checkpoint.get('vocab_size', tokenizer.vocab_size),\n",
    "        embed_dim=128,\n",
    "        perceiver_model=perceiver\n",
    "    )\n",
    "\n",
    "    packnet_model = PackNet(combined_model)\n",
    "    packnet_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    packnet_model.to(device)\n",
    "    packnet_model.set_task(f\"group_{group_idx}_evaluation\")\n",
    "    print(\"Pruned model loaded successfully.\")\n",
    "\n",
    "    return packnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pruned model for Group 1 from /home/jisoo/Perceiver/Perceiver/checkpoints/group_1_pruned_model.pth.tar...\n",
      "Pruned model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_154851/1335650828.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1: Test Loss: 18.7532, Test Accuracy: 0.3382\n",
      "Loading pruned model for Group 2 from /home/jisoo/Perceiver/Perceiver/checkpoints/group_2_pruned_model.pth.tar...\n",
      "Pruned model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_154851/1335650828.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 2: Test Loss: 9.8228, Test Accuracy: 0.3210\n",
      "Loading pruned model for Group 3 from /home/jisoo/Perceiver/Perceiver/checkpoints/group_3_pruned_model.pth.tar...\n",
      "Pruned model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_154851/1335650828.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 3: Test Loss: 12.4661, Test Accuracy: 0.3651\n",
      "Loading pruned model for Group 4 from /home/jisoo/Perceiver/Perceiver/checkpoints/group_4_pruned_model.pth.tar...\n",
      "Pruned model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_154851/1335650828.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 4: Test Loss: 11.8579, Test Accuracy: 0.3530\n",
      "Loading pruned model for Group 5 from /home/jisoo/Perceiver/Perceiver/checkpoints/group_5_pruned_model.pth.tar...\n",
      "Pruned model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_154851/1335650828.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 5: Test Loss: 10.0594, Test Accuracy: 0.3360\n",
      "Loading pruned model for Group 6 from /home/jisoo/Perceiver/Perceiver/checkpoints/group_6_pruned_model.pth.tar...\n",
      "Pruned model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_154851/1335650828.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 6: Test Loss: 13.2638, Test Accuracy: 0.3376\n"
     ]
    }
   ],
   "source": [
    "def evaluate_pruned_model(packnet_model, test_loader, criterion, device):\n",
    "    packnet_model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = packnet_model(input_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "checkpoint_dir = \"/home/jisoo/Perceiver/Perceiver/checkpoints\"\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "for group_idx in range(1, len(output_paths) + 1):\n",
    "    # dataloader 불러오기\n",
    "    test_loader, label_encoder = prepare_test_loader(group_idx, batch_size=32)\n",
    "\n",
    "    pruned_model = load_pruned_model(group_idx, checkpoint_dir, device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # evaluate\n",
    "    test_loss, test_accuracy = evaluate_pruned_model(pruned_model, test_loader, criterion, device)\n",
    "    print(f\"Group {group_idx}: Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
