{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import copy, math\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.utils import _pair\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from models.shared_perceiver import crop, patchify, get_patch_coords, ImageDataset, PerceiverBlock, Perceiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed) #torch를 거치는 모든 난수들의 생성순서를 고정한다\n",
    "    torch.cuda.manual_seed(seed) #cuda를 사용하는 메소드들의 난수시드는 따로 고정해줘야한다 \n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True #딥러닝에 특화된 CuDNN의 난수시드도 고정 \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed) #numpy를 사용할 경우 고정\n",
    "    random.seed(seed) #파이썬 자체 모듈 random 모듈의 시드 고정\n",
    "\n",
    "def seed_worker(worker_id): #데이터로더 난수고정\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(42)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "NUM_WORKERS = 4 # 서브프로세스관리자 수. 난수생성과 관련있습니다. 일단은 4로 고정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(dataloader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(dataloader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, train_loader, valid_loader, criterion, optimizer, epochs, device, scheduler=None):\n",
    "#     best_model = None \n",
    "#     best_val_score = 0\n",
    "#     model.train()\n",
    "#     train_losses = []\n",
    "#     val_accuracies = []\n",
    "#     start = time.perf_counter()\n",
    "    \n",
    "#     for epoch in range(epochs):\n",
    "#         total_loss = 0.0\n",
    "#         for images, labels in train_loader:\n",
    "#             # GPU로 옮기기\n",
    "#             images = images.to(device)\n",
    "#             labels = labels.to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "#         avg_loss = total_loss / len(train_loader)\n",
    "#         train_losses.append(avg_loss)\n",
    "\n",
    "#         accuracy = evaluate_model(model, valid_loader, device=device, log_results=False)\n",
    "#         val_accuracies.append(accuracy)\n",
    "\n",
    "#         # Scheduler step 추가\n",
    "#         if scheduler:\n",
    "#             scheduler.step()\n",
    "\n",
    "#         print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Val Accuracy: {accuracy:.2f}%\")\n",
    "#         if accuracy > best_val_score:\n",
    "#             best_val_score = accuracy\n",
    "#             best_model_state = model.state_dict()  # 모델 상태 저장\n",
    "#             best_model = copy.deepcopy(model) \n",
    "#             print(f\"New best model found at epoch {epoch+1} with accuracy: {best_val_score:.2f}%\")\n",
    "\n",
    "#     end = time.perf_counter()\n",
    "#     hour = (end-start) // 3600\n",
    "#     min = ((end-start) % 3600) // 60\n",
    "#     sec = int((end-start) % 60)\n",
    "#     print(f\"Total Train time: {hour}h {min}m {sec}s\")\n",
    "\n",
    "#     return train_losses, val_accuracies, best_model\n",
    "\n",
    "# def evaluate_model(model, data_loader, device, log_results=True):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         start = time.perf_counter()\n",
    "#         for images, labels in data_loader:\n",
    "#             images = images.to(device)\n",
    "#             labels = labels.to(device)\n",
    "\n",
    "#             outputs = model(images)\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#         end = time.perf_counter()\n",
    "#         hour = (end-start) // 3600\n",
    "#         min = ((end-start) % 3600) // 60\n",
    "#         sec = (end-start) % 60\n",
    "#         print(f\"Elapsed time on CPU: {hour}h {min}m {sec}s\")\n",
    "\n",
    "#     accuracy = 100.0 * correct / total\n",
    "#     if log_results:\n",
    "#         print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "#     return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/youlee/n24news/n24news/image'\n",
    "CROP_SIZE = 16\n",
    "PATCH_SIZE = 16\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "EPOCHS = 40\n",
    "K_FOLDS = 5\n",
    "GROUP_CLASS = 3\n",
    "LR = 5e-5\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Opinion',\n",
       " 'Art & Design',\n",
       " 'Television',\n",
       " 'Music',\n",
       " 'Travel',\n",
       " 'Real Estate',\n",
       " 'Books',\n",
       " 'Theater',\n",
       " 'Health',\n",
       " 'Sports',\n",
       " 'Science',\n",
       " 'Food',\n",
       " 'Fashion & Style',\n",
       " 'Movies',\n",
       " 'Technology',\n",
       " 'Dance',\n",
       " 'Media',\n",
       " 'Style']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random.shuffle(target_classes)\n",
    "target_classes = [ # 임의로 순서지정\n",
    "    \"Opinion\", \"Art & Design\", \"Television\",\n",
    "    \"Music\", \"Travel\", \"Real Estate\",\n",
    "    \"Books\", \"Theater\", \"Health\",\n",
    "    \"Sports\", \"Science\", \"Food\",\n",
    "    \"Fashion & Style\", \"Movies\", \"Technology\",\n",
    "    \"Dance\", \"Media\", \"Style\"\n",
    "]\n",
    "target_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/home/Minju/Perceiver/shared_layer_model'\n",
    "loader_path = '/home/Minju/Perceiver/shared_layer_loader'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_learning_curves = []\n",
    "best_models = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kfold(task_id, dataset, num_classes, device, output_path, loader_path):\n",
    "    kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(dataset), start=1):\n",
    "        print(f\"\\nFold {fold}/{K_FOLDS} 진행 중...\")\n",
    "        \n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        test_subset = Subset(dataset, test_idx)\n",
    "        \n",
    "        train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        model = Perceiver(\n",
    "            input_dim=(PATCH_SIZE**2) * 3 + 2,\n",
    "            latent_dim=64,\n",
    "            latent_size=64,\n",
    "            num_classes=num_classes,\n",
    "            num_blocks=4,\n",
    "            self_attn_layers_per_block=10\n",
    "        ).to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "        \n",
    "        train_losses, test_losses = [], []\n",
    "        train_accuracies, test_accuracies = [], []\n",
    "        best_model = None\n",
    "        best_test_acc = 0.0\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            test_loss, test_acc = eval_epoch(model, test_loader, criterion, device)\n",
    "            train_losses.append(train_loss)\n",
    "            test_losses.append(test_loss)\n",
    "            train_accuracies.append(train_acc)\n",
    "            test_accuracies.append(test_acc)\n",
    "            scheduler.step()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "            \n",
    "            if test_acc > best_test_acc:\n",
    "                best_test_acc = test_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "        \n",
    "        # Save best model\n",
    "        torch.save(best_model, f\"{output_path}/image_model_{task_id}_fold{fold}.pkl\")       # bugfix: 현재는 각 fold에서 best model 저장.\n",
    "        \n",
    "        # Save DataLoader\n",
    "        with open(f\"{loader_path}/image_val_loader_{task_id}_fold{fold}.pkl\", \"wb\") as f:   # bugfix: 현재는 각 fold의 valid loader 저장.\n",
    "            pickle.dump(test_subset, f)\n",
    "        \n",
    "        # Evaluate final model on test set\n",
    "        y_true, y_pred = [], []\n",
    "        best_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = best_model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        report = classification_report(y_true, y_pred, output_dict=True)\n",
    "        \n",
    "        results.append({\n",
    "            \"Fold\": fold,\n",
    "            \"Test Accuracy\": best_test_acc,\n",
    "            \"Confusion Matrix\": cm,\n",
    "            \"Classification Report\": report\n",
    "        })\n",
    "        \n",
    "        all_learning_curves.append({\n",
    "            \"Fold\": fold,\n",
    "            \"train_losses\": train_losses,\n",
    "            \"test_losses\": test_losses,\n",
    "            \"train_accuracies\": train_accuracies,\n",
    "            \"test_accuracies\": test_accuracies\n",
    "        })\n",
    "        \n",
    "        # Plot Learning Curve\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, EPOCHS + 1), train_losses, label=\"Train Loss\")\n",
    "        plt.plot(range(1, EPOCHS + 1), test_losses, label=\"Test Loss\")\n",
    "        plt.title(f\"Fold {fold} Learning Curve (Loss)\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(range(1, EPOCHS + 1), train_accuracies, label=\"Train Accuracy\")\n",
    "        plt.plot(range(1, EPOCHS + 1), test_accuracies, label=\"Test Accuracy\")\n",
    "        plt.title(f\"Fold {fold} Learning Curve (Accuracy)\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot Confusion Matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title(f\"Fold {fold} Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"\\n=== K-Fold 결과 요약 ===\")\n",
    "    for result in results:\n",
    "        print(f\"Fold {result['Fold']} - Test Accuracy: {result['Test Accuracy']:.4f}\")\n",
    "        print(pd.DataFrame(result[\"Classification Report\"]).transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실험 1 시작\n",
      "Selected Feature: ['Opinion', 'Art & Design', 'Television']\n",
      "Unique numeric labels: [0 1 2]\n",
      "Number of unique numeric labels: 3\n",
      "Label distribution (index: count): Counter({np.int64(1): 2437, np.int64(0): 2431, np.int64(2): 2419})\n",
      "\n",
      "Fold 1/5 진행 중...\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(target_classes), GROUP_CLASS):  \n",
    "    print(f\"실험 {i//GROUP_CLASS + 1} 시작\")\n",
    "    selected_classes = target_classes[i:i+GROUP_CLASS]\n",
    "    print(f\"Selected Feature: {selected_classes}\")\n",
    "\n",
    "    filtered_dataset = ImageDataset(root_dir=data_dir, \n",
    "                                    transform=transform, \n",
    "                                    crop_size=CROP_SIZE, \n",
    "                                    patch_size=PATCH_SIZE,\n",
    "                                    selected_classes=selected_classes)\n",
    "    all_labels = [label_idx for (_, label_idx) in filtered_dataset.data]\n",
    "\n",
    "    # 1) 유니크 라벨과 개수\n",
    "    unique_label_ids = np.unique(all_labels)\n",
    "    print(\"Unique numeric labels:\", unique_label_ids)\n",
    "    print(\"Number of unique numeric labels:\", len(unique_label_ids))\n",
    "\n",
    "    # 2) 라벨별 개수 (분포)\n",
    "    label_counts = Counter(all_labels)\n",
    "    print(\"Label distribution (index: count):\", label_counts)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    NUM_CLASSES = len(label_counts)\n",
    "\n",
    "    train_kfold(i+1, filtered_dataset, NUM_CLASSES, device, output_path, loader_path)\n",
    "    \n",
    "    # train_ratio = 0.8\n",
    "    # train_size = int(len(filtered_dataset) * train_ratio)\n",
    "    # valid_size = len(filtered_dataset) - train_size\n",
    "\n",
    "\n",
    "    # train_dataset, valid_dataset = random_split(filtered_dataset, [train_size, valid_size])\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    #                           num_workers=NUM_WORKERS, worker_init_fn=seed_worker, generator=g)\n",
    "    # valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    #                           num_workers=NUM_WORKERS, worker_init_fn=seed_worker, generator=g)\n",
    "\n",
    "    # print(f\"train: {train_size}, valid: {valid_size}\")\n",
    "    \n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # NUM_CLASSES = len(filtered_dataset.label_encoder.classes_)\n",
    "    # model = Perceiver(input_dim=(PATCH_SIZE**2) * 3 + 2,\n",
    "    #                     latent_dim=64, \n",
    "    #                     latent_size=64, \n",
    "    #                     num_classes=NUM_CLASSES, \n",
    "    #                     num_blocks=4, \n",
    "    #                     self_attn_layers_per_block=10).to(device)\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # Learning rate decay 추가\n",
    "\n",
    "    # start = time.perf_counter()\n",
    "    # train_losses, val_accuracies, best_model = train_model(\n",
    "    #     model, train_loader, valid_loader,\n",
    "    #     criterion, optimizer, EPOCHS,\n",
    "    #     device=device,\n",
    "    #     scheduler=scheduler  \n",
    "    # )\n",
    "    \n",
    "    # final_acc = evaluate_model(best_model, valid_loader, device=device, log_results=True)\n",
    "    # end = time.perf_counter()\n",
    "    # hour = (end-start) // 3600\n",
    "    # min = ((end-start) % 3600) // 60\n",
    "    # sec = int((end-start) % 60)\n",
    "    # print(f\"Train time: {hour}h {min}m {sec}s\")\n",
    "    # print(f\"Final Validation Accuracy: {final_acc:.2f}%\")\n",
    "    # print(\"----------------------------------------------------------\")\n",
    "    \n",
    "    # torch.save(best_model, f'{output_path}/image_model_{i//GROUP_CLASS+1}.pkl')\n",
    "\n",
    "    # val_loader_save_path = f\"{loader_path}/image_val_loader_{i//GROUP_CLASS+1}.pkl\"\n",
    "    # with open(val_loader_save_path, 'wb') as f:\n",
    "    #     pickle.dump(valid_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
