import torch
import torch.nn as nn
import torch.optim as optim
from collections import OrderedDict
from torch.utils.data import DataLoader
import pickle
import random
import numpy as np
import pandas as pd
import os

def seed_everything(seed):
    torch.manual_seed(seed) #torchë¥¼ ê±°ì¹˜ëŠ” ëª¨ë“  ë‚œìˆ˜ë“¤ì˜ ìƒì„±ìˆœì„œë¥¼ ê³ ì •í•œë‹¤
    torch.cuda.manual_seed(seed) #cudaë¥¼ ì‚¬ìš©í•˜ëŠ” ë©”ì†Œë“œë“¤ì˜ ë‚œìˆ˜ì‹œë“œëŠ” ë”°ë¡œ ê³ ì •í•´ì¤˜ì•¼í•œë‹¤ 
    torch.cuda.manual_seed_all(seed)  # if use multi-GPU
    torch.backends.cudnn.deterministic = True #ë”¥ëŸ¬ë‹ì— íŠ¹í™”ëœ CuDNNì˜ ë‚œìˆ˜ì‹œë“œë„ ê³ ì • 
    torch.backends.cudnn.benchmark = False
    np.random.seed(seed) #numpyë¥¼ ì‚¬ìš©í•  ê²½ìš° ê³ ì •
    random.seed(seed) #íŒŒì´ì¬ ìì²´ ëª¨ë“ˆ random ëª¨ë“ˆì˜ ì‹œë“œ ê³ ì •

def seed_worker(worker_id): #ë°ì´í„°ë¡œë” ë‚œìˆ˜ê³ ì •
    worker_seed = torch.initial_seed() % 2**32
    np.random.seed(worker_seed)
    random.seed(worker_seed)

seed_everything(42)
g = torch.Generator()
g.manual_seed(42)
NUM_WORKERS = 4 # ì„œë¸Œí”„ë¡œì„¸ìŠ¤ê´€ë¦¬ì ìˆ˜. ë‚œìˆ˜ìƒì„±ê³¼ ê´€ë ¨ìˆìŠµë‹ˆë‹¤. ì¼ë‹¨ì€ 4ë¡œ ê³ ì •í•©ë‹ˆë‹¤.

# Perceiver ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
import sys
sys.path.append("/home/jisoo/Perceiver/code")
from perceiver import crop, patchify, get_patch_coords, ImageDataset, PerceiverBlock, Perceiver, CustomDataset, CombinedModel
torch.serialization.add_safe_globals([CombinedModel])

# SparsePruner ê°€ì ¸ì˜¤ê¸°
sys.path.append("/home/jisoo/Perceiver/code")
from sparse_pruner_packnet import SparsePruner

root_dir = '/home/jisoo/Perceiver/model/'
loader_dir = '/home/jisoo/Perceiver/loader/'
batch_size = 32

input_models = OrderedDict()
valid_loaders = OrderedDict()

for i in range(6):
    model_path = root_dir + f"text_model_{i+1}.pkl"
    try:
        input_models[f"text_model_{i+1}"] = torch.load(model_path, map_location="cpu", weights_only=False)
        print(f"í…ìŠ¤íŠ¸ ëª¨ë¸ {i+1} ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {model_path}")
    except AttributeError as e:
        print(f"*ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"*`weights_only=True`ë¡œ ë‹¤ì‹œ ë¡œë“œ ì‹œë„")
        model_weights = torch.load(model_path, map_location="cpu", weights_only=True)

        # Perceiver ëª¨ë¸ì„ ìƒˆë¡œ ìƒì„±í•˜ê³  ê°€ì¤‘ì¹˜ ì ìš©
        model = Perceiver(input_dim=768, latent_dim=512, latent_size=128, num_classes=100, num_blocks=6, self_attn_layers_per_block=2)
        model.load_state_dict(model_weights)

        input_models[f"text_model_{i+1}"] = model
        print(f"í…ìŠ¤íŠ¸ ëª¨ë¸ {i+1} (weights-only) ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {model_path}")


for i in range(6):
    model_path = root_dir + f"image_model_{i+1}.pkl"
    input_models[f"image_model_{i+1}"] = torch.load(model_path, map_location="cpu", weights_only=False)
    print(f"image model {i+1} ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {model_path}")

for i in range(6):
    loader_path = loader_dir + f"text_val_loader_{i+1}.pkl"
    with open(loader_path, "rb") as f:
        valid_loaders[f"text_loader_{i+1}"] = pickle.load(f)
    print(f"text data loader {i+1} ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {loader_path}")

for i in range(6):
    loader_path = loader_dir + f"image_val_loader_{i+1}.pkl"
    with open(loader_path, "rb") as f:
        loaded_valid_dataset = pickle.load(f)

    valid_loaders[f"image_loader_{i+1}"] = DataLoader(loaded_valid_dataset, batch_size=batch_size, shuffle=False)
    print(f"image data loader {i+1} ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {loader_path}")


class Manager:
    """Handles pruning, fine-tuning, and inference for Perceiver models."""

    def __init__(self, args, model, previous_masks):
        self.args = args
        self.device = torch.device("cuda" if args.cuda and torch.cuda.is_available() else "cpu")
        self.model = model.to(self.device)

        # ì´ì „ íƒœìŠ¤í¬ì˜ ë§ˆìŠ¤í¬ ë¶ˆëŸ¬ì˜¤ê¸°
        self.previous_masks = previous_masks
        self.criterion = nn.CrossEntropyLoss()

        # PackNet ë°©ì‹ìœ¼ë¡œ Pruningì„ ìœ„í•œ SparsePruner ì„¤ì •
        self.pruner = SparsePruner(
            model=self.model,
            prune_perc=self.args.prune_perc,
            previous_masks=self.previous_masks,
            train_bias=False,
            train_bn=False
        )

    def prune(self):
        """Perform pruning on the model."""
        print("** Pruning ì‹œì‘...")
        self.pruner.prune()
        print("** Pruning í›„ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€...")
        self.eval()

    def train(self, train_loader, optimizer, epochs):
        """Train the model with fine-tuning."""
        print("** Finetuningì„ ìœ„í•œ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")

        for epoch in range(epochs):
            self.model.train()
            total_loss = 0

            for batch in train_loader:
                inputs = batch["input_ids"].to(self.device).float()
                attention_mask = batch["attention_mask"].to(self.device).float()
                labels = batch["labels"].to(self.device)

                inputs = inputs.reshape(inputs.shape[0], -1)
                attention_mask = attention_mask.reshape(attention_mask.shape[0], -1)

                # ë°±ë³¸ ëª¨ë¸ì´ `image_model_`ì´ê³ , ë°ì´í„° ë¡œë”ê°€ `text_loader_`ì¼ ë•Œë§Œ
                if "image_model" in self.args.backbone_model and "text_loader" in self.args.data_loader:
                    inputs = torch.nn.functional.pad(inputs, (0, 770 - 128))  # (B, 128) â†’ (B, 770)

                if inputs.dim() == 2: # ì…ë ¥ ì°¨ì› (B, F) -> (B, 1, F)
                    inputs = inputs.unsqueeze(1)

                optimizer.zero_grad()
                outputs = self.model(inputs)
                loss = self.criterion(outputs, labels)
                loss.backward()

                # PackNet: pruningëœ ê°€ì¤‘ì¹˜ëŠ” ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šë„ë¡ ì²˜ë¦¬
                self.pruner.make_grads_zero()
                optimizer.step()

                # pruningëœ ê°€ì¤‘ì¹˜ëŠ” í•­ìƒ 0ìœ¼ë¡œ ìœ ì§€
                self.pruner.make_pruned_zero()

                total_loss += loss.item()

            print(f"Epoch {epoch+1}: Loss={total_loss:.4f}")

        print("Finetuning ì™„ë£Œ!")

    def eval(self):
        """Evaluate the model after pruning and fine-tuning."""
        print("** ëª¨ë¸ í‰ê°€ ì‹œì‘...")
        self.model.eval()

        correct = 0
        total = 0
        with torch.no_grad():
            for batch in self.args.test_loader:
                inputs = batch["input_ids"].to(self.device).float()
                attention_mask = batch["attention_mask"].to(self.device).float()
                labels = batch["labels"].to(self.device) 

                inputs = inputs.reshape(inputs.shape[0], -1)
                attention_mask = attention_mask.reshape(attention_mask.shape[0], -1)

                self.pruner.apply_mask(self.pruner.current_dataset_idx)

                if inputs.dim() == 2: # ì…ë ¥ ì°¨ì› (B, F) -> (B, 1, F)
                    inputs = inputs.unsqueeze(1)
                
                # ë°±ë³¸ ëª¨ë¸ì´ `image_model_`ì´ê³ , ë°ì´í„° ë¡œë”ê°€ `text_loader_`ì¼ ë•Œë§Œ
                if "image_model" in self.args.backbone_model and "text_loader" in self.args.data_loader:
                    inputs = torch.nn.functional.pad(inputs, (0, 770 - 128))  # (B, 128) â†’ (B, 770)


                outputs = self.model(inputs)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        accuracy = 100 * correct / total
        print(f"ëª¨ë¸ í‰ê°€ ì™„ë£Œ - Accuracy: {accuracy:.2f}%")
        return accuracy

    def save_model(self, save_path):
        """Save the model after training."""
        print("** ëª¨ë¸ ì €ì¥ ì¤‘...")
        torch.save(self.model.state_dict(), save_path)
        print(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}")


#  ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (Pickle íŒŒì¼ì—ì„œ `DataLoader` ë¶ˆëŸ¬ì˜¤ê¸°)
def load_dataloader(pkl_path):
    print(f"ğŸ”¹ {pkl_path}ì—ì„œ DataLoader ë¡œë“œ ì¤‘...")
    with open(pkl_path, "rb") as f:
        dataloader = pickle.load(f)
    return dataloader


# ì‹¤í–‰ ì½”ë“œ
def packnet_train_prune_infer(args, save_path):
    device = torch.device("cuda" if args.cuda and torch.cuda.is_available() else "cpu")

    # 1. ë°±ë³¸ ëª¨ë¸ ë¡œë“œ (`image_model_2.pkl`)
    # print("ë°±ë³¸ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    # model = CombinedModel(vocab_size=30522, embed_dim=768, perceiver_model=Perceiver(
    #     input_dim=768,       # BERT ê¸°ë°˜ í…ìŠ¤íŠ¸ ì…ë ¥ ì°¨ì› ë˜ëŠ” ì´ë¯¸ì§€ íŒ¨ì¹˜ ì°¨ì›
    #     latent_dim=512,      # Perceiverì˜ Latent ì°¨ì›
    #     latent_size=128,     # Latent ê°œìˆ˜
    #     num_classes=100,     # âœ… Perceiver ëª¨ë¸ ë‚´ì—ì„œ num_classesë¥¼ ì§€ì •
    #     num_blocks=6,        # Perceiver ë¸”ë¡ ê°œìˆ˜
    #     self_attn_layers_per_block=2   # Self-Attention ë ˆì´ì–´ ê°œìˆ˜
    # )).to(device)
    # model_checkpoint = torch.load("/home/jisoo/Perceiver/model/image_model_2.pkl", map_location=device, weights_only=True)

    # model.load_state_dict(model_checkpoint)

    # 1. ë°±ë³¸ ëª¨ë¸ ë¡œë“œ (`image_model_2.pkl`)
    print("** ë°±ë³¸ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    model = input_models["image_model_2"].to(device)

    # 2. PackNet ë°©ì‹ìœ¼ë¡œ ë°±ë³¸ ëª¨ë¸ì—ì„œ Pruning ìˆ˜í–‰
    print("** ë°±ë³¸ ëª¨ë¸ì—ì„œ Pruning ìˆ˜í–‰...")
    previous_masks = OrderedDict()
    for module_idx, module in enumerate(model.modules()):
        if isinstance(module, nn.Linear):
            previous_masks[module_idx] = torch.ones_like(module.weight.data).to(device)

    manager = Manager(args, model, previous_masks)
    manager.prune()

    print("** Fine-tuningì„ ìœ„í•œ Pruning Mask ì ìš©...")
    manager.pruner.make_finetuning_mask()

    # 3. Text ë°ì´í„°ë¡œ Finetuning (`text_val_loader_1.pkl`)
    print("** `valid_loaders`ì—ì„œ ë°ì´í„° ë¡œë” ê°€ì ¸ì˜¤ê¸°...")
    text_loader = valid_loaders["text_loader_1"]

    print("** Text ë°ì´í„°ë¡œ Finetuning ì‹œì‘...")
    optimizer = optim.Adam(model.parameters(), lr=args.lr)
    manager.train(text_loader, optimizer, args.epochs)

    # 4. Inference ìˆ˜í–‰
    print("** Inference ê²€ì¦ ì‹œì‘...")
    accuracy = manager.eval()
    print(f"ìµœì¢… Accuracy: {accuracy:.2f}%")

    # 5. ìµœì¢… ëª¨ë¸ ì €ì¥
    manager.save_model(save_path)

class Args:
    cuda = True
    num_classes = 100
    prune_perc = 0.1
    lr = 1e-4
    epochs = 20
    backbone_model = "image_model_2" 
    data_loader = "text_loader_1" 
    test_loader = load_dataloader("/home/jisoo/Perceiver/loader/text_val_loader_1.pkl")  # Inferenceë¥¼ ìœ„í•œ ë°ì´í„° ë¡œë“œ

args = Args()
packnet_train_prune_infer(
    args,
    save_path="/home/jisoo/Perceiver/model/packnet_finetuned_model.pth"
)