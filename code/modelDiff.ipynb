{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pdb\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "import copy\n",
    "from scipy import spatial\n",
    "import csv\n",
    "\n",
    "from perceiver import crop, patchify, get_patch_coords, ImageDataset, PerceiverBlock, Perceiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed) #torch를 거치는 모든 난수들의 생성순서를 고정한다\n",
    "    torch.cuda.manual_seed(seed) #cuda를 사용하는 메소드들의 난수시드는 따로 고정해줘야한다 \n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True #딥러닝에 특화된 CuDNN의 난수시드도 고정 \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed) #numpy를 사용할 경우 고정\n",
    "    random.seed(seed) #파이썬 자체 모듈 random 모듈의 시드 고정\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/Minju/Perceiver/model/'\n",
    "loader_dir = '/home/Minju/Perceiver/loader/'\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text model 1번 불러오기 완료.\n",
      "Text val. loader 0번 불러오기 완료.\n",
      "Text model 2번 불러오기 완료.\n",
      "Text val. loader 1번 불러오기 완료.\n",
      "Text model 3번 불러오기 완료.\n",
      "Text val. loader 2번 불러오기 완료.\n",
      "Text model 4번 불러오기 완료.\n",
      "Text val. loader 3번 불러오기 완료.\n",
      "Text model 5번 불러오기 완료.\n",
      "Text val. loader 4번 불러오기 완료.\n",
      "Text model 6번 불러오기 완료.\n",
      "Text val. loader 5번 불러오기 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145447/2580130533.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  text_model = torch.load(root_dir + f'text_model_{i+1}.pkl')\n"
     ]
    }
   ],
   "source": [
    "input_models = []\n",
    "valid_loaders = []\n",
    "for i in range (6):\n",
    "    text_model = torch.load(root_dir + f'text_model_{i+1}.pkl')\n",
    "    input_models.append(text_model)\n",
    "    print(f\"Text model {i+1}번 불러오기 완료.\")\n",
    "\n",
    "    with open(loader_dir+f'text_val_loader_{i+1}.pkl', 'rb') as f:\n",
    "        loaded_valid_dataset = pickle.load(f)\n",
    "    \n",
    "    valid_loader = DataLoader(loaded_valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    valid_loaders.append(valid_loader)\n",
    "    print(f\"Text val. loader {i}번 불러오기 완료.\")\n",
    "\n",
    "# for i in range(6):\n",
    "#     img_model = torch.load(root_dir + f'image_model_{i}.pkl')\n",
    "#     input_models.append(img_model)\n",
    "#     print(f\"Image model {i}번 불러오기 완료.\")\n",
    "\n",
    "#     with open(loader_dir+f'image_val_loader_{i}.pkl', 'rb') as f:\n",
    "#         loaded_valid_dataset = pickle.load(f)\n",
    "\n",
    "#     valid_loader = DataLoader(loaded_valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "#     valid_loaders.append(valid_loader)\n",
    "#     print(f\"Image val. loader {i}번 불러오기 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ModelDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = -1\n",
    "lr = 0.1\n",
    "batch_size = 32\n",
    "val_batch_size = 100\n",
    "workers = 24\n",
    "weight_decay = 4e-5\n",
    "dataset_name = ''\n",
    "train_path = ''\n",
    "val_path = ''\n",
    "cuda = True\n",
    "seed = 1\n",
    "epochs = 160\n",
    "restore_epoch = 0\n",
    "save_folder = ''\n",
    "load_folder = ''\n",
    "one_shot_prune_perc = 0.5\n",
    "mode = ''\n",
    "logfile = ''\n",
    "initial_from_task = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\n",
    "    'Opinion','Art & Design','Television',\n",
    "    'Music','Travel','Real Estate',\n",
    "    'Books','Theater','Health',\n",
    "    'Sports','Science','Food',\n",
    "    'Fashion & Style','Movies','Technology',\n",
    "    'Dance', 'Media', 'Style'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "max_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유사도검색"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task_id 책정방식: \\\n",
    "0~5 : text modality \\\n",
    "6~11: image modality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: 특정 input data로 유사도 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ddv_cos(model1, model2, inputs):\n",
    "    global outputs\n",
    "    global outputs2\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        dists = []\n",
    "        outputs = model1(torch.Tensor(inputs).cuda()).to('cpu').tolist()\n",
    "        n_pairs = int(len(list(inputs)) / 2)\n",
    "        for i in range(n_pairs):\n",
    "            ya = outputs[i]\n",
    "            yb = outputs[i + n_pairs]\n",
    "            dist = spatial.distance.cosine(ya, yb)\n",
    "            dists.append(dist)\n",
    "\n",
    "        dists2 = []\n",
    "        outputs2 = model2(torch.Tensor(inputs).cuda()).to('cpu').tolist()\n",
    "        n_pairs2 = int(len(list(inputs)) / 2)\n",
    "        for i in range(n_pairs2):\n",
    "            ya = outputs2[i]\n",
    "            yb = outputs2[i + n_pairs]\n",
    "            dist = spatial.distance.cosine(ya, yb)\n",
    "            dists2.append(dist)\n",
    "    return np.array(dists), np.array(dists2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ddv_euc(model1, model2, inputs):\n",
    "    global outputs\n",
    "    global outputs2\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        dists = []\n",
    "        outputs = model1(torch.Tensor(inputs).cuda()).to('cpu').tolist()\n",
    "        n_pairs = int(len(list(inputs)) / 2)\n",
    "        for i in range(n_pairs):\n",
    "            ya = outputs[i]\n",
    "            yb = outputs[i + n_pairs]\n",
    "            dist = spatial.distance.euclidean(ya, yb) # dist = spatial.distance.cosine(ya, yb)\n",
    "            dists.append(dist)\n",
    "\n",
    "        dists2 = []\n",
    "        outputs2 = model2(torch.Tensor(inputs).cuda()).to('cpu').tolist()\n",
    "        n_pairs2 = int(len(list(inputs)) / 2)\n",
    "        for i in range(n_pairs2):\n",
    "            ya = outputs2[i]\n",
    "            yb = outputs2[i + n_pairs]\n",
    "            dist = spatial.distance.euclidean(ya, yb) # dist = spatial.distance.cosine(ya, yb)\n",
    "            dists2.append(dist)\n",
    "    return np.array(dists), np.array(dists2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### compute_similarity #####\n",
    "def compute_sim_cos(ddv1, ddv2):\n",
    "    return spatial.distance.cosine(ddv1, ddv2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_id \u001b[38;5;241m==\u001b[39m target_id:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch)\n\u001b[1;32m     11\u001b[0m inputs \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# 첫 번째 배치의 입력만 사용\u001b[39;00m\n",
      "File \u001b[0;32m/home/Minju/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/home/Minju/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/home/Minju/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/home/Minju/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "ddvcc_list = []\n",
    "ddvec_list = []\n",
    "\n",
    "for task_id in range(6):\n",
    "    if task_id == target_id:\n",
    "        continue\n",
    "\n",
    "\n",
    "    batch = next(iter(valid_loaders[target_id]))  \n",
    "    print(batch)\n",
    "    inputs = batch['input_ids']  # 첫 번째 배치의 입력만 사용\n",
    "\n",
    "    ddv1, ddv2 = compute_ddv_cos(input_models[target_id], input_models[task_id], inputs)\n",
    "    ddv_distance = compute_sim_cos(ddv1, ddv2)\n",
    "    print('DDV cos-cos [%d => %d] %.5f'%(task_id, target_id, ddv_distance))\n",
    "    ddvcc_list.append(ddv_distance)\n",
    "\n",
    "    # DDV-EC\n",
    "    ddv1, ddv2 = compute_ddv_euc(input_models[target_id], input_models[task_id], inputs)\n",
    "    ddv_distance = compute_sim_cos(ddv1, ddv2)\n",
    "    print('DDV euc-cos [%d => %d] %.5f'%(task_id, target_id, ddv_distance))\n",
    "    ddvec_list.append(ddv_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: latent vector로 유사도 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
