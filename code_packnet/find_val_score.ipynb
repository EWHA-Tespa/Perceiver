{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from perceiver import crop, patchify, get_patch_coords, tokenize_data, CustomDataset, PerceiverBlock, Perceiver, CombinedModel, ImageDataset\n",
    "\n",
    "# Device 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed) #torch를 거치는 모든 난수들의 생성순서를 고정한다\n",
    "    torch.cuda.manual_seed(seed) #cuda를 사용하는 메소드들의 난수시드는 따로 고정해줘야한다 \n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True #딥러닝에 특화된 CuDNN의 난수시드도 고정 \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed) #numpy를 사용할 경우 고정\n",
    "    random.seed(seed) #파이썬 자체 모듈 random 모듈의 시드 고정\n",
    "\n",
    "def seed_worker(worker_id): #데이터로더 난수고정\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(42)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "NUM_WORKERS = 4 # 서브프로세스관리자 수. 난수생성과 관련있습니다. 일단은 4로 고정합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/home/youlee/perceiver/perceiver'\n",
    "\n",
    "model_path = root_path + '/model/'\n",
    "loader_path = root_path + '/loader/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_text_accuracy(model, data_loader, device):\n",
    "    model.eval()  # 평가 모드로 전환\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            # 배치가 dict 형태인 경우 올바른 키 사용\n",
    "            if isinstance(batch, dict):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                # 모델이 attention_mask를 필요로 한다면 함께 전달\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "            else:\n",
    "                # 만약 tuple/list 형태로 구성되어 있다면, 상황에 맞게 수정\n",
    "                input_ids, labels = batch[0].to(device), batch[1].to(device)\n",
    "                attention_mask = None  # 필요 시 추가\n",
    "\n",
    "            # 모델 호출 (attention_mask가 필요하면 전달)\n",
    "            if attention_mask is not None:\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            else:\n",
    "                outputs = model(input_ids)\n",
    "\n",
    "            # 예: outputs가 각 클래스에 대한 로짓이라면 argmax를 통해 예측 클래스 결정\n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_image_accuracy(model, data_loader, device):\n",
    "    model.eval()  # 평가 모드로 전환\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # 평가 시에는 기울기 계산하지 않음\n",
    "        for batch in data_loader:\n",
    "            inputs, labels = batch\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)  \n",
    "\n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 model, loader 불러오기 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3272473/3670095996.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_pos, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 모델의 validation accuracy: 0.8519\n",
      "\n",
      "Task 1 model, loader 불러오기 완료\n",
      "Task 1 모델의 validation accuracy: 0.8171\n",
      "\n",
      "Task 2 model, loader 불러오기 완료\n",
      "Task 2 모델의 validation accuracy: 0.8444\n",
      "\n",
      "Task 3 model, loader 불러오기 완료\n",
      "Task 3 모델의 validation accuracy: 0.8725\n",
      "\n",
      "Task 4 model, loader 불러오기 완료\n",
      "Task 4 모델의 validation accuracy: 0.8705\n",
      "\n",
      "Task 5 model, loader 불러오기 완료\n",
      "Task 5 모델의 validation accuracy: 0.7869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    model_pos = model_path + f'text_model_{i}.pkl'\n",
    "    model = torch.load(model_pos, map_location=device)\n",
    "    model.to(device)\n",
    "    loader_pos = loader_path + f'text_val_loader_{i}.pkl'\n",
    "    with open(loader_pos, 'rb') as f:\n",
    "        loader = pickle.load(f)\n",
    "    print(f'Task {i-1} model, loader 불러오기 완료')\n",
    "\n",
    "    val_acc = calculate_text_accuracy(model, loader, device)\n",
    "    print(f'Task {i-1} 모델의 validation accuracy: {val_acc:.4f}\\n')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 6 model, loader 불러오기 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3272473/64437764.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_pos, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 6 모델의 validation accuracy: 0.7003\n",
      "\n",
      "Task 7 model, loader 불러오기 완료\n",
      "Task 7 모델의 validation accuracy: 0.6356\n",
      "\n",
      "Task 8 model, loader 불러오기 완료\n",
      "Task 8 모델의 validation accuracy: 0.5809\n",
      "\n",
      "Task 9 model, loader 불러오기 완료\n",
      "Task 9 모델의 validation accuracy: 0.6121\n",
      "\n",
      "Task 10 model, loader 불러오기 완료\n",
      "Task 10 모델의 validation accuracy: 0.6144\n",
      "\n",
      "Task 11 model, loader 불러오기 완료\n",
      "Task 11 모델의 validation accuracy: 0.5353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    model_pos = model_path + f'image_model_{i}.pkl'\n",
    "    model = torch.load(model_pos, map_location=device)\n",
    "    model.to(device)\n",
    "    \n",
    "    loader_pos = loader_path + f'image_val_loader_{i}.pkl'\n",
    "    with open(loader_pos, 'rb') as f:\n",
    "        loader_data = pickle.load(f)\n",
    "    valid_loader = DataLoader(loader_data, batch_size=batch_size, shuffle=False,\n",
    "                            num_workers=NUM_WORKERS, worker_init_fn=seed_worker, generator=g)\n",
    "    print(f'Task {i+5} model, loader 불러오기 완료')\n",
    "\n",
    "    val_acc = calculate_image_accuracy(model, valid_loader, device)\n",
    "    print(f'Task {i+5} 모델의 validation accuracy: {val_acc:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
